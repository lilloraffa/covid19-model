<!doctype html><html><head><meta charset="utf-8">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js">
<link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
<link rel="stylesheet" href="https://gitcdn.xyz/repo/goessner/mdmath/master/css/texmath.css">
<link rel="stylesheet" href="https://gitcdn.xyz/repo/goessner/mdmath/master/css/vscode-texmath.css">

</head><body>
<h1 id="model-worksheet-2" data-line="0" class="code-line">Model worksheet</h1>
<p data-line="2" class="code-line">This is a worksheet to write considerations on model characteristics and performance, and to keep track of findings from
calibration.</p>
<h2 id="calibration-2" data-line="8" class="code-line">Calibration</h2>
<p data-line="9" class="code-line">We have two calibration on going:</p>
<ul>
<li data-line="10" class="code-line">structural: started with big grid, still running. Strategy: use as starting point to evaluate how perturbation on some
group of parameters interfers with others and with overall model performance</li>
<li data-line="12" class="code-line">fast: used for both testing/bug fixing, and to test, starting from initial model (should be the structural one)
testing parameter perturbation / effects on the model</li>
</ul>
<h3 id="to-test-2" data-line="17" class="code-line">To Test</h3>
<ul>
<li data-line="18" class="code-line">try a time decay mechanism for error calculation, so to weight recent errors more (prob helps with predictability)</li>
<li data-line="19" class="code-line">error function definition and its impact on training performance and predict performance</li>
<li data-line="20" class="code-line">try to put some contraints on grid and parameters based on observations (i.e. especially on t1, ti2, etc)
<ul>
<li data-line="21" class="code-line">t1, ta2 --&gt; between 2 and 14 days (fonte ECDC)</li>
<li data-line="22" class="code-line">alpha, beta, gamma must be less than 1</li>
</ul>
</li>
</ul>
<h3 id="current-calibration-2" data-line="24" class="code-line">Current calibration</h3>
<p data-line="25" class="code-line">Goal: find the optimal grid space for all parameters, globally (understand if for some initial grid value or for some
region there are strange situations)
Model 10: err1 abs</p>
<ul>
<li data-line="28" class="code-line">structural: ongoing
<ul>
<li data-line="29" class="code-line">saved model &quot;ModReg_v10-Struct&quot;</li>
<li data-line="30" class="code-line">study:
<ul>
<li data-line="31" class="code-line">Do the same analysis done for fast and compare with it</li>
<li data-line="32" class="code-line">Analyze the performance of the model fixing t1, t2, Igs_t, Ias_t to see what happens to other parameter and
to error</li>
</ul>
</li>
</ul>
</li>
<li data-line="34" class="code-line">fast: ongoing
<ul>
<li data-line="35" class="code-line">saved model &quot;ModReg_v10-fast&quot;
study:
<ul>
<li data-line="37" class="code-line">Look at model performance (also error based) in general for every regions and national
<ul>
<li data-line="38" class="code-line">Look at statistics for every model and describe it for every model, so to have a summary of each model
(then we will compare it with the struct when ready)</li>
<li data-line="40" class="code-line">Create error graphs for Igc_cum, Igc, Gc, M for every model and see if there are patterns</li>
</ul>
</li>
<li data-line="41" class="code-line">regional models and national: parameter sensibility --&gt; try to find patterns and explainations on strange
solutions
<ul>
<li data-line="43" class="code-line">create scatter plot with pairwise parameters, color is the value of the error --&gt; see if there are
correlations between parameters and between them and errors</li>
</ul>
</li>
<li data-line="45" class="code-line">t1, tgi2, ecc Analysis: analyze the sensibility of other params and on performance based on given values of t1, t12, etc.</li>
<li data-line="46" class="code-line">check if initial starting point between model and act data is correct.
results:</li>
<li data-line="48" class="code-line">It seems that extreme values of rg and ra are correlated with higher error model --&gt; what is the optimal interval?</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="lesson-learned-2" data-line="55" class="code-line">Lesson learned</h3>
<ul>
<li data-line="56" class="code-line">Error: we tested difference in model performance (national model) by using different error definitions
<ul>
<li data-line="57" class="code-line">err1: normal value (no functions applied). abs vs perc: it is the absolute difference between actual and model vs
percentage diff. pen: inclusion of a penality calculated based on total value, to be added to singolar error</li>
<li data-line="59" class="code-line">Results:
<ul>
<li data-line="60" class="code-line">tot
<ul>
<li data-line="61" class="code-line">err1 with abs gives relatively good performance, window is always better</li>
<li data-line="62" class="code-line">err1 with perc seems to be unbalanced towards guariti and intensiva. Window is not working well...
M_cum model seems to diverge more rapidly (increasing) than in the abs case.
Predictions seems to have slower pace in the perc case than in the abs one. Perc also explodes in terms of
deaths.
With perc, tot model window dos not work
Generally speaking, model tot with abs err1 seems to be working better as a whole. Other model may be better for
specific variables.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="known-issues-2" data-line="75" class="code-line">Known issues</h2>
<ul>
<li data-line="76" class="code-line">forzare in tutte le parti del codice che t1 &lt; tgi2, tgn2! --&gt; prob ci sono problemi nel finetuning</li>
<li data-line="77" class="code-line">check everywhere that ta2 is always greater than 2</li>
<li data-line="78" class="code-line">fix the discrete step in FinetuneParams to take into account differences in delta (now increment is only 1)</li>
<li data-line="79" class="code-line">last part of the window seems to be not set to the last value</li>
<li data-line="80" class="code-line">Fix the statistics part to take into account the initial value of both data model (this should be already done) and actual data (to be investigated, you should make the data start since the point identified when actual data are created (probably saved))</li>
</ul>
<h1 id="fixing-2" data-line="87" class="code-line">Fixing</h1>
<h2 id="testing-strategy-2" data-line="89" class="code-line">Testing strategy</h2>
<ul>
<li data-line="90" class="code-line">Create a new version of the library for testing</li>
<li data-line="91" class="code-line">Analyze and fix one problem at a time!</li>
<li data-line="92" class="code-line">Create a notebook for testing one region at a time, start with national
<ul>
<li data-line="93" class="code-line">fix bugs first
<ul>
<li data-line="94" class="code-line">fix the statistics part to allow for initial point in actual data</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="todo-2" data-line="97" class="code-line">ToDo</h2>
<ul>
<li data-line="98" class="code-line">Create aggregate model from all regional one</li>
<li data-line="99" class="code-line">Study Fast Calibration done yesterday</li>
<li data-line="100" class="code-line">Study Struct Calibration done last time</li>
<li data-line="101" class="code-line">Put official population data for each region</li>
<li data-line="102" class="code-line">Think of a procedure to evaluate prediction performance (save a given model trained on a given date and compare with forecast using new data every day. Do this for every models)</li>
</ul>
<h2 id="investigate--notes-2" data-line="104" class="code-line">Investigate / notes</h2>
<ul>
<li data-line="105" class="code-line">ParamFinetuner - (err_delta = err_prev if err_new == 0.0 else (err_prev - err_new)/err_new) is it correct?</li>
<li data-line="106" class="code-line">Why do rg and ra change after window optimization? --&gt; because it is set like this at the beginning of Optimizer</li>
<li data-line="107" class="code-line">IMPORTANT: need to study better how the error funciton should work!!! it seems that the percentage error may create bias towards small numbers</li>
</ul>

</body></html>